\section{Game Theory}
Game Theory is the study of rational behavior in situations involving interdependence as it may involve:
\begin{itemize}
\item Common interest (coordination);
\item Competing interests (rivalry);
\item Rational behavior: players can do the best they can, in their own eyes;
\item Because of the players' interdependence, a rational decision in a game must be based on a prediction of others' responses;
\end{itemize}
\clearpage

\subsection{The parts of a Game} 
A Game consists of three parts : 
Players, Actions and Payoffs
\subsubsection{Players}
Players are the decision makers and they can be : People, Governments or Companies.
\subsubsection{Actions}
What can the players do ?
Decide when to sell a stock, decide how to vote or enter a bid in an auction...
\subsubsection{Payoffs}
Payoffs can represent the motivation of the players, for example : Do they care about profit ? or Do they care about other players ? 

\subsection{Defining Games} Games can be represented in two methods : Normal forms and Extensive Forms.

\subsection{Extensive Form}
An extensive form game includes timing of moves. 
Players move sequentially, represented as a tree.
\begin{itemize}
\item Chess: white player moves, then black player can see white's move and react...
\end{itemize}
Keeps track of what each player knows when he or she makes a decision :
\begin{itemize}
\item Poker: bet sequentially - what can a given player see when they bet. 
\end{itemize}

\subsection{Normal Form Games}
\paragraph{}A normal form game is a strategic interaction in which each of $n$ players chooses a strategy and the receives a payoff that depends on all agents choices of strategy. In other words, a normal form represents a list of what players get on function of their actions.
Finite, n-person normal form game  ⟨$N, A, u$⟩:
\begin{itemize}
\item Players: $ N = {1, ... , n} $ is a finite set of $n$, indexed by $i$.
\item Actions set for player $i$ $A_i$
\subitem $a = (a_1,...,a_n) \in A = A_1 * ... * A_n $ is an action profile.
\item Utility function or Payoff function for player $i: u_i : A $  $\to$ ${\Bbb{R}}$
\subitem $u = (u_1,..., u_n)$, is a profile of utility functions.
\end{itemize}

\subsection{Best Response and Nash Equilibrium}\label{subsection}
\paragraph{Best Response :}
\begin{equation}\label{eq:1}
 a_i^* \in BR(a_{-i})  iff   \forall a_i \in A_i, u_i(a_i^*,a_{-i}) \geq u_i(a_i, a_{-i})
\end{equation}
 
\paragraph{Nash Equilibrium (Definition):}
$a = <a_1,...,a_n>$ is a "\textbf{pure strategy}" if $\forall i, a_i \in BR(a_{-i})$

\subsection{Dominant strategies}
let $s_i$ and $s_i^`$ be two strategies for player $i$, and let $S_{-i}$ be the set of all possible strategy profiles for other players.
\bigbreak
\title{\textbf{Definitions:} }
\begin{itemize}
\item $s_i$ \textbf{strictly dominates} $s_i^`$ if $\forall s_{-i} \in S_{-i}, u_i(s_i, s_{-i}) \>> u_i(s_i^`, s_{-i})$
\item $s_i$ \textbf{very weakly dominates} $s_i^`$ if $\forall s_{-i} \in S_{-i}, u_i(s_i, s_{-i}) \geq u_i(s_i^`, s_{-i})$
\item A strategy is called \textbf{dominant} if it dominates all others.
\item A strategy profile consisting of dominant strategies for every player must be a Nash Equilibrium.
\end{itemize}

\subsection{Pareto Optimal}
\title{\textbf{Definition:}}
An outcome $o^*$ is \textbf{Pareto-optimal} if there is no other outcome that Pareto-dominates it.

\section{Mixed Strategies and Nash Equilibrium}
\title{\textbf{Definition:}}
A strategy $s_i$ for agent $i$ as any probability distribution over the actions $A_i$.
\begin{itemize}
\item \textbf{pure strategy:} only one action is played with positive probability
\item \textbf{mixed strategy:} more than one action is played with positive probability
\bigbreak
these actions are called the support of the mixed strategy.
\item Let the set of all strategies for $i$ be $S_i$
\item let the set of all strategy profiles be $S = S_1 \times... \times S_n$
\end{itemize}

\subsection{Utility in Mixed Strategies}
In order to find the payoff if all the players follow mixed strategy profile $s \in S$ we can use the \textbf{expected utility} from decision theory: 
\begin{equation} u_i(s) = \sum_{a \in A}u_i(a)P(a|s)\end{equation}
\begin{equation} P(a|s) = \prod_{j \in N}s_j(a_j)\end{equation}

\subsection{Best Response and Nash Equilibrium}The definitions of best response and Nash equilibrium are generalized from actions to strategies. 
\paragraph{Definition (Best Response): }
\begin{equation}
s_i^* \in BR(s_{-i}) \textbf{ if }   \forall s_i \in S_i, u_i(s_i^*,s_{-i}) \geq u_i(s_i, s_{-i})
\end{equation}
\paragraph{Definition (Nash Equilibrium)}
$$s = <s_1,...,s_n>\textbf{ is  a }\textbf{Nash Equilibrium if } \forall i, s_i \in BR(s_{-i})$$
\paragraph{Theorem (Nash, 1950)} Every finite game has a Nash equilibrium.

\subsection{Computing Nash Equilibrium}
\paragraph{Two algorithms for finding NE }
\begin{itemize}
\item LCP(Linear Complimentary) [Lemke-Howson].
\item Support Enumeration Method [Porter et al].
\end{itemize}

\subsection{Complexity Analysis}
\title{\textbf{Theorem:}}
Computing a Nash Equilibrium is a \textbf{PPAD-complete}\footnote{PPAD : Polynomial Parity Argument on Directed Graphs} , this theorem has been proven for:
\begin{itemize}
\item for games $\geq$ 4 players;
\item for games with 3 players;
\item for games with 2 players;
\end{itemize}

\subsection{Summary of mixed strategies}
\begin{itemize}
\item Some games have mixed strategy Nash Equilibria.
\item A player must be indifferent between the actions he or she randomizes over.
\item Randomization happen in business interactions, society, sports...
\end{itemize}

\subsection{Strictly Dominated Strategies}
\paragraph{Definition}a strategy $a_i \in A_i $ is strictly dominated by $a'_i \in A_i$ if
\begin{equation} u_i(a_i, a_{-i}) < u_i(a'_i, a_{-i}) ,  \forall   a_{-i} \in A_{-i} \end{equation}

\subsection{Weakly Dominated Strategies}
\paragraph{Definition}a strategy $a_i \in A_i $ is weakly dominated by $a'_i \in A_i$ if
\begin{equation} u_i(a_i, a_{-i}) \leq u_i(a'_i, a_{-i}) ,  \forall   a_{-i} \in A_{-i} \end{equation}
\begin{center}
and 
\end{center}
\begin{equation} u_i(a_i, a_{-i}) < u_i(a'_i, a_{-i}) ,\exists   a_{-i} \in A_{-i} \end{equation} 

\section{Perfect information games}{The extensive form is an alternative representation that makes the temporal structure explicit.}
\begin{itemize}
\item{Perfect information extensive form games.}
\item{Imperfect information extensive form games.}
\end{itemize}
\title {\textbf{Definition}} A finite perfect information game in extensive form is defined by the tuple ($N, A, H, Z,\chi ,\rho, \sigma, u $)
where:
\begin{itemize}
\item{Players: $N$ is a set of $n$ players.}
\item{Actions: $A$ is set of actions.}
\item{Choice nodes and labels for these nodes: }
\begin{itemize}
\item{Choice nodes: $H$ is a set of non-terminal choice nodes.}
\item{Action function: $\chi : H \to 2^A $ assigns to each choice a set of actions.}
\item{Player function: $\rho : H \to N$ assigns to each non-terminal node $h$ a player $i \in N$ who chooses an action at $h$.}
\end{itemize}
\item{Terminal nodes: $Z$ is a set of terminal nodes, disjoint from $H$.}
\item{Successor function: $\sigma : H \times A \to H \cup Z$ maps a choice node and an action to a new choice node or terminal node such that for all $h_1, h_2 \in H$ and $a_1, a_2 \in A$, if $\sigma(h_1, a_1) = \sigma(h_2, a_2)$ then $h_1  = h_2$  and $a_1 = a_2$} 
\item{Utility function: $u = (u_1,...,u_n)$ where $u_i : Z \to R$
}
\end{itemize} 
\paragraph{}figure \ref{fig:scaled_diss} shows a sharing game represented in the extensive form
\begin{figure}[h]
 
  \centering
  \begin{tikzpicture}[baseline] % baseline makes the example number stay at the top of the tree
   \Tree[.1 [.\textit{2 } [.\textit{(0,0) } ] [.\textit{(2,0) } ]][.\textit{2 } [.\textit{(0,0) } ] [.\textit{(1,1) } ]][.\textit{2 } [.\textit{(0,0) } ] [.\textit{(0,2) } ]]]
     \end{tikzpicture}%
  \caption{Sharing Game\label{fig:scaled_diss}}
\end{figure}
\subsection{Pure Strategies}
\paragraph{} A pure strategy for a player in a perfect-information game is a complete specification of which action to take at each node belonging to that player.
\paragraph{Definition} Let $G = (N, A, H, Z,\chi ,\rho, \sigma, u ) $ be a perfect-information extensive-form game. Then the pure strategies of player $i$ consist of the cross product\\
\begin{center}
$ \prod_{h \in H, \rho(h)=i}\chi(h)$
\end{center}
\paragraph{}
Given our new definition of pure strategy, we can reuse our old definitions of mixed strategies and Nash equilibrium in \ref{eq:1}.

\subsection{Sub-game Perfection}
\begin{mydef}[Sub-game Perfection]\label{def:def555}
The set of sub-games of $G$ is defined by the sub-games of $G$ rooted at each of the nodes in $G$.
\end{mydef}
\paragraph{}Let $s$ be a  sub-game perfect equilibrium of $G$ if for any sub-game $G'$ of $G$, the restriction of $s$ to G' is a Nash Equilibrium of $G'$. Since $G$ is its own sub-game , every sub-game perfect is a Nash Equilibrium.

\subsection{Backward Induction}

\begin{algorithm}{h}
\caption{Backward Induction\label{fig:scaled_back}}
\begin{algorithmic}
\RETURN $u(h)$
\IF{$h \in Z$}
\RETURN{$u(h)$}
\ENDIF
\STATE $best-util \leftarrow -50$
\FORALL{$a \in \rho(h)$} 
\STATE $util-at-child \leftarrow BACKWARDINDUCTION(\sigma(h,a))$ 
\IF{$util-at-child_p(h) >best-util_p(h)$}
\STATE $best-util \leftarrow util-at-child$
\ENDIF
\ENDFOR
\RETURN $best-util$
\end{algorithmic}
\end{algorithm}
\paragraph{}Backward Induction has been used in solving games since John von Neumann and Oskar Morgenstern published their book, Theory of Games and Economic Behaviors in 1944.
\paragraph{}The idea behind Backward Induction is to identify the equilibrium in the buttom trees, and adopt these as one moves up the tree as the next algorithm shows.


\paragraph{} Denote $util_at_child$ is a utility vector for each player.
\section{Evolutionary Game Theory}

\paragraph{}Evolution and Game Theory was introduced by John Maynard Smith in Evolution and The Theory of Games. The Theory was formulated to understand the behavior of animals in game theoretic situations. But it can be applied to modeling human behavior.

\paragraph{}After the emergence of traditional game theory, biologists realized the potential of game theory to formally study adaptation and convolution of biological populations, especially in contexts where the fitness of a phenotype depends on the composition of the population (Hamilton, 1967). The main assumption of evolutionary game theory was that strategies with greater payoffs at a particular time would tend to spread more and thus have better chances of being present in the future.
\paragraph{}The most important concept of evolutionary thinking that was introduced by Manynard Smith and Price (1973) is the notion of \textbf{Evolutionary Stable Strategy}(ESS), for 2-player symmetric games played by individuals belonging to the same population. Furthermore, a strategy $s$ is an ESS if and only if, when adopted by all members of a population, meaning that any other strategy $i$ that could enter the population in a low percentage would obtain a strictly  lower expected payoff in the population than the $s$ strategy.
\paragraph{}The basic ideas behind Evolutionary game theory is that strategies with greater payoffs tend to spread more, and that fitness is frequency dependent soon transcended the borders of biology and started to spread through many other disciplines. In economic context, it was understood that natural selection would derive from competition among entities for small resources or market shares. In social contexts, evolution was often understood as cultural evolution, and it referred to dynamic changes in behavior or ideas over time (\cite{Nelson and Winter, 1982})(\cite{Boyd and Richerson, 1985}).
\paragraph{}In order to extend this understanding further, let's consider this example:
Suppose that a small group of mutants choosing a strategy different from $\delta$* to enter the population.
\begin{itemize}
\item Denote the fraction of mutants in the population by $\varepsilon$ and assume that the mutant adopts the strategy $\delta$.
\item The expected payoff of a mutant is : 
	$(1-\varepsilon)u(\delta,\delta*)+\varepsilon u(\delta*,\delta)$
\item The expected payoff of a mutant that adopts the strategy is :	\\
	$(1-\varepsilon)u(\delta*,\delta*)+\varepsilon u(\delta*,\delta)$
	\item For any mutation to be driven out of the population we need the expected payoff of any mutant to be less than the expected payoff of normal organism :\\
	\begin{equation}(1-\varepsilon)u(\delta*,\delta*)+\varepsilon u(\delta*,\delta) > (1-\varepsilon)u(\delta,\delta*)+\varepsilon u(\delta*,\delta)  \end{equation}
\end{itemize}
\subsection{Static Notions of Evolutionary Stability}
\paragraph{}Maynard Smith offered a stability concept for populations of animals sharing a common behavioral trait, that of player a mixed strategy in  the game. Maynard defines such a population as stable if it is resistant to invasion by a small group of mutants carrying a different strategy(Sandholm, 2017).
\paragraph{}Suppose that a large population is randomly matched to play the symmetric normal form game $A$. We call a mixed strategy $x \in X$ an \textbf{evolutionarily stable strategy} (ESS) if 
\begin{equation}\label{eq:5}
x' A((1 - \epsilon)x + \epsilon y) > y' A((1 - \epsilon)x + \epsilon y) 
\end{equation}
\begin{center}
$\forall \epsilon \leq \epsilon(y)$ and $y \neq x.$
\end{center}
\paragraph{}In order to explain condition \ref{eq:5}, let's consider a population programmed to play mixed strategy $x$ is invaded by a small group of mutants programmed to play the alternative mixed strategy $y$. Equation \ref{eq:5} requires that regardless of the choice of $y$, an incumbent's expected payoff from a random match in the post entry population exceeds that of a mutant so long as the size of the invading group is sufficiently small.
\paragraph{}The definition of ESS above can also be expressed as a combination of two conditions: 
\begin{equation}\label{eq:6}
x' A x \geq y' A x  \: \forall  \: y \in X
\end{equation}
\begin{center}
For all $y \neq x.$
\end{center}
\begin{equation}\label{eq:7}
[x' A x = y' A x] \implies [x' A y > y' A y]
\end{equation}
\paragraph{}Condition \ref{eq:6} requires that the incumbent strategy $x$ be a best response to itself. Condition \ref{eq:7} requires that if a mutant strategy $y$ is an alternative best response against the incumbent strategy $x$ then the incumbent ears a higher payoff against the mutant than the mutant earns against itself.
\paragraph{}Maynard Smith's notion of ESS attempts to capture the dynamic process of natural selection using a static definition.

\section{Population Games}
\paragraph{}Population games provide a simple and general framework for studying strategic interactions in large populations whose members play pure strategies. The simplest population games are generated by random matching in normal form games, but the population game framework allows for interactions of a more intricate nature.
\paragraph{}We focus here on games played by a single population. All agents in this game play equivalent roles. We suppose that there is a unit mass of agents, each of whom chooses a pure strategy from the set
 $S = {1, ... , n}$. The aggregate behavior of these agents is described by a population state $x \in X$, with $x_j$ representing the proportion of agents choosing pure strategy $j$. We identify a population game with a continuous vector valued payoff function $ F:X \rightarrow R^n$. The scalar $F(x)$ represents the payoff to strategy $i$ when the population state is $x$.
\paragraph{}Population state $x^*$ is a Nash Equilibrium of $F$ if no agent can improve his payoff by unilaterally switching strategies.